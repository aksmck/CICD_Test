CREATE TABLE IF NOT EXISTS $$unity_catalog_name.$$schema_name.$$delta_table_name (
  NDC_NUM STRING COMMENT 'National Drug Code Number',
  GNRC_NAM STRING COMMENT 'Generic Name',
  PREV_NDC_NUM STRING COMMENT 'Previous NDC Number',
  OBSOLETE_DT TIMESTAMP COMMENT 'Obsolete Date',
  DOSE_FORM_DSCR STRING COMMENT 'Dose Form Description',
  DRG_STRNTH_DSCR STRING COMMENT 'Drug Strength Description',
  GNRC_IND STRING COMMENT 'Generic Indicator',
  GNRC_CD_NUM STRING COMMENT 'Generic Code Number',
  THERA_CLS_CD STRING COMMENT 'Therapeutic Class Code',
  SPECIFIC_THERA_CLS_CD STRING COMMENT 'Specific Therapeutic Class Code',
  PKG_SIZ DECIMAL(38,18) COMMENT 'Package Size',
  DRG_FORM_CD STRING COMMENT 'Drug Form Code',
  ADMIN_RTE_CD STRING COMMENT 'Admin Rate Code',
  GNRC_CD_NUM_SEQ STRING COMMENT 'Generic Code Number Sequence',
  REPL_NDC_NUM STRING COMMENT 'Repl. NDC Number',
  DEA_CD STRING COMMENT 'DEA Code',
  ADTL_DSCR STRING COMMENT 'Additional Description',
  BRND_NAM STRING COMMENT 'Brand Name',
  GNRC_PRC_IND STRING COMMENT 'Generic Price Indicator',
  LBL_NAM STRING COMMENT 'Label Name',
  MFR_NAM STRING COMMENT 'Manufacturer Name',
  NDC_CNFG_IND STRING COMMENT 'NDC Configuration Indicator',
  PKG_DSCR STRING COMMENT 'Package Description',
  RTE_DSCR STRING COMMENT 'Rate Description',
  TOP_200_IND STRING COMMENT 'Top 200 Indicator',
  UNIT_DOSE_IND STRING COMMENT 'Unit Dose Indicator',
  FFP_UL_CUR_EFF_DT TIMESTAMP COMMENT 'FFP UL Current Effective Date',
  FFP_UL_CUR_UNIT_PRC DECIMAL(38,18) COMMENT 'FFP UL Current Unit Price',
  GNRC_THERA_CLS_CD STRING COMMENT 'Generic Therapeutic Class Code',
  STD_THERA_CLS_CD STRING COMMENT 'Standard Therapeutic Class Code',
  DRG_CLS_CD STRING COMMENT 'Drug Class Code',
  INGR_CD_NUM STRING COMMENT 'Ingredient Code Number',
  ORANGE_BOOK_CD STRING COMMENT 'Orange Book Code',
  CUR_BLU_BOOK_EFF_DT TIMESTAMP COMMENT 'Current BLU Book Effective Date',
  CUR_BLU_BOOK_UNIT_PRC DECIMAL(38,18) COMMENT 'Current BLU Book Unit Price',
  CUR_BLU_BOOK_PKG_DT TIMESTAMP COMMENT 'Current BLU Book Package Date',
  CUR_BLU_BOOK_PKG_PRC DECIMAL(38,18) COMMENT 'Current BLU Book Package Price',
  LBLR_ID STRING COMMENT 'LBLR Identifier',
  PATENT_EXPIR_DT TIMESTAMP COMMENT 'Patent Expiration Date',
  EXCLUSIVITY_EXPIR_DT TIMESTAMP COMMENT 'Exclusivity Expiration Date',
  DRG_STRNTH_NUM DECIMAL(38,18) COMMENT 'Drug Strength Number',
  SHLF_PACK_NUM BIGINT COMMENT 'Shelf Pack Number',
  PATIENT_PKG_ISRT_IND STRING COMMENT 'Patient Package Insert Indicator',
  DSPNS_CNT DECIMAL(38,18) COMMENT 'Dispense Count',
  UPDT_DTS TIMESTAMP COMMENT 'Update Date',
  CRTE_DTS TIMESTAMP COMMENT 'Create Date',
  _rescued_data STRING,
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pieline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'This is extracted from the input file name of source',
  DATABRICKS_RUN_ID STRING COMMENT 'run id of the Databricks job run. This gets generated from the bronze notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'job id of the Databricks job run. This gets generated from the bronze notebook run',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from date part of the RECORD_LOAD_TIME column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This is autogenerated from hour part of the RECORD_LOAD_TIME column'
) 
USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION '$$delta_table_location' 
TBLPROPERTIES (
  'delta.feature.allowColumnDefaults' = 'supported',
  'delta.feature.appendOnly' = 'supported',
  'delta.feature.invariants' = 'supported',
  'delta.minReaderVersion' = '1',
  'delta.minWriterVersion' = '7',
  'spark.sql.files.ignoreMissingFiles'=true
);