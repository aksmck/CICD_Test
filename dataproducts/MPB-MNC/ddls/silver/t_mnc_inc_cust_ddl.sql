CREATE TABLE IF NOT EXISTS $$unity_catalog_name.$$schema_name.$$delta_table_name (
  CLIENT STRING COMMENT 'Client; SOURCE : MANDT',
  APPLICATION STRING COMMENT 'Application; SOURCE : KAPPL',
  EXCLSN_TYPE STRING COMMENT 'Material listing/exclusion type; SOURCE : KSCHL',
  SLS_ORG STRING COMMENT 'Sales Organization Code; SOURCE : VKORG',
  CUST_ACCT_ID STRING COMMENT 'Customer Account ID; SOURCE : KUNNR',
  MNC_CD STRING COMMENT 'Membership Network Code; SOURCE : YYMEM_NETWRK',
  EXPR_DT DATE COMMENT 'Expiration Date; SOURCE : DATBI',
  EFFCTV_DT DATE COMMENT 'Effective Date; SOURCE : DATAB',
  _rescued_data STRING,
  ADF_RUN_ID STRING COMMENT 'ID for specific pipeline run loaded from landing. This run_id gets generated when the records gets loaded from source to landing',
  ADF_JOB_ID STRING COMMENT 'ID of the trigger that invokes the pieline. This job_id gets generated when the records gets loaded from source to landing',
  RECORD_LOAD_TIME TIMESTAMP DEFAULT current_timestamp COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INPUT_FILE_NAME STRING COMMENT 'File name which is getting populated from bronze layer',
  DATABRICKS_RUN_ID STRING COMMENT 'run id of the Databricks job run. This gets generated from the silver notebook run',
  DATABRICKS_JOB_ID STRING COMMENT 'job id of the Databricks job run. This gets generated from the silver notebook run',
  INSERT_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  UPDATE_TS TIMESTAMP COMMENT 'This is the default generated column using current timestamp when the record is loaded in the table',
  INTEGRATION_KEY STRING COMMENT 'Hash key created using combination of all the columns except the housekeeping columns',
  DATE_PART DATE GENERATED ALWAYS AS (DATE(RECORD_LOAD_TIME)) COMMENT 'This the date part generated from Record load time column',
  HOUR_PART INT GENERATED ALWAYS AS (HOUR(RECORD_LOAD_TIME)) COMMENT 'This the hour  part generated from Record load time column'
) USING DELTA PARTITIONED BY (DATE_PART, HOUR_PART) LOCATION '$$delta_table_location' TBLPROPERTIES (
'delta.feature.allowColumnDefaults' = 'supported',
'delta.feature.appendOnly' = 'supported',
'delta.feature.invariants' = 'supported',
'delta.minReaderVersion' = '1',
'delta.minWriterVersion' = '7',
'delta.enableChangeDataFeed' = true,
'spark.sql.files.ignoreMissingFiles' = true,
'delta.autoOptimize.optimizeWrite' = true);