name: Databricks Deployment

on:
  workflow_dispatch:
    inputs:
      ENV:
        type: string
        required: true
      date:
        type: string
        required: true
      databricks_deployment_steps:
        type: string
        required: true
      SOURCE:
        type: string
        required: true

env:
  ENV: ${{ inputs.ENV }}
  DATE: ${{ inputs.date }}
  SOURCE: ${{ inputs.SOURCE }}
  BRANCH: ${{ github.event.inputs.BRANCH || github.ref_name }} # Default to current branch if not provided

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ env.BRANCH }} # Ensure the correct branch is checked out

      # Step to get changed files since the specified date
      - name: Get changed files since
        id: changed-files-since
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: |
            # Check for changes in common/utils/ if ingestion_utilities is selected
            ${{ contains(inputs.databricks_deployment_steps, 'ingestion_utilities') && 'common/utils/' || '' }}
            
            # Check for changes in dataproducts/${{ inputs.SOURCE }}/ddls/ if ddl is selected
            ${{ contains(inputs.databricks_deployment_steps, 'ddl') && 'dataproducts/${{ inputs.SOURCE }}/ddls/' || '' }}
            
            # Check for changes in dataproducts/${{ inputs.SOURCE }}/dmls/ if dml is selected
            ${{ contains(inputs.databricks_deployment_steps, 'dml') && 'dataproducts/${{ inputs.SOURCE }}/dmls/' || '' }}

      - name: Install Databricks CLI
        run: |
          pip install --upgrade databricks-cli

      - name: Setup Databricks ENV
        run: |
          case "${{ env.ENV }}" in
            dev)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_DEV }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_DEV }}" >> $GITHUB_ENV
              ;;
            qat)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_QAT }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_QAT }}" >> $GITHUB_ENV
              ;;
            prod)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_PROD }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_PROD }}" >> $GITHUB_ENV
              ;;
          esac

      - name: Deploy Databricks Files
        run: |
          BASE_PATH="/Workspace/Users/s2ek20b@mckesson.com/CICD_TEST"
          echo "Deploying to Databricks for ENV: ${{ env.ENV }} after date: ${{ env.DATE }}"

          if [[ "${{ inputs.databricks_deployment_steps }}" == "ingestion_utilities" || "${{ inputs.databricks_deployment_steps }}" == "all" ]]; then
              echo "Deploying Ingestion Utilities..."
              databricks workspace import_dir "common/utils/" "${BASE_PATH}/common/utils/" --overwrite 
          fi

          if [[ "${{ inputs.databricks_deployment_steps }}" == "ddl" || "${{ inputs.databricks_deployment_steps }}" == "all" ]]; then
              echo "Deploying DDL files..."
              databricks workspace import_dir "dataproducts/${{ inputs.SOURCE }}/ddls/" "${BASE_PATH}/dataproducts/${{ inputs.SOURCE }}/ddls/" --overwrite 
          fi

          if [[ "${{ inputs.databricks_deployment_steps }}" == "dml" || "${{ inputs.databricks_deployment_steps }}" == "all" ]]; then
              echo "Deploying DML files..."
              databricks workspace import_dir "dataproducts/${{ inputs.SOURCE }}/dmls/" "${BASE_PATH}/dataproducts/${{ inputs.SOURCE }}/dmls/" --overwrite 
          fi

      - name: Clean up temporary directories
        run: |
          echo "Cleaning up temporary directories..."
          rm -rf /tmp/cu/py/
          rm -rf /tmp/cu/ddl_dml/
