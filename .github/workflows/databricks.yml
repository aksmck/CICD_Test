name: Databricks Deployment

on:
  workflow_dispatch:
    inputs:
      ENV:
        description: 'ENV'
        type: string
        required: true
      date:
        description: 'Commit date'
        type: string
        required: true
      deployment_steps:
        description: 'Deployment steps (e.g., ingestion_utilities, ddl, dml, or all)'
        type: string
        required: true
      SOURCE:
        description: 'SOURCE directory'
        type: string
        required: true

env:
  ENV: ${{ inputs.ENV }}
  DATE: ${{ inputs.date }}
  SOURCE: ${{ inputs.SOURCE }}
  BRANCH: ${{ github.ref_name }}

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ env.BRANCH }}

      - name: Install Databricks CLI
        run: |
          pip install --upgrade databricks-cli

      - name: Setup Databricks ENV
        run: |
          case "${{ env.ENV }}" in
            dev)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_DEV }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_DEV }}" >> $GITHUB_ENV
              ;;
            qat)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_QAT }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_QAT }}" >> $GITHUB_ENV
              ;;
            prod)
              echo "DATABRICKS_HOST=${{ secrets.DATABRICKS_HOST_PROD }}" >> $GITHUB_ENV
              echo "DATABRICKS_TOKEN=${{ secrets.DATABRICKS_TOKEN_PROD }}" >> $GITHUB_ENV
              ;;
          esac

      - name: Get changed files since specified date
        id: changed-files
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: |
            ${{ inputs.deployment_steps == 'ingestion_utilities' || inputs.deployment_steps == 'all' && 'common/utils/' || '' }}
            ${{ inputs.deployment_steps == 'ddl' || inputs.deployment_steps == 'all' && 'dataproducts/${{ inputs.SOURCE }}/ddls/' || '' }}
            ${{ inputs.deployment_steps == 'dml' || inputs.deployment_steps == 'all' && 'dataproducts/${{ inputs.SOURCE }}/dmls/' || '' }}

      - name: Validate and Debug Files
        run: |
          CHANGED_FILES="${{ steps.changed-files.outputs.all_changed_files }}"
          echo "Changed files: $CHANGED_FILES"

          if [[ -z "$CHANGED_FILES" ]]; then
            echo "No changed files detected. Exiting."
            exit 0
          fi

          for file in $CHANGED_FILES; do
            echo "Validating file: $file"
            if [[ "$file" == *.py ]]; then
              python -m py_compile "$file"
              if [[ $? -ne 0 ]]; then
                echo "Syntax error in $file"
                exit 1
              fi
            elif [[ "$file" == *.ipynb ]]; then
              # Check if the notebook is valid JSON
              if ! jq empty "$file" >/dev/null; then
                echo "Invalid notebook JSON structure in $file"
                exit 1
              fi
            else
              echo "Skipping unsupported file type: $file"
            fi
          done

      - name: Deploy to Databricks
        run: |
          BASE_PATH="/Workspace/Users/username@example.com/CICD_TEST"

          for step in ingestion_utilities ddl dml; do
            if [[ "${{ inputs.deployment_steps }}" == "$step" || "${{ inputs.deployment_steps }}" == "all" ]]; then
              case "$step" in
                ingestion_utilities)
                  SOURCE_PATH="common/utils/"
                  TARGET_PATH="${BASE_PATH}/common/utils/"
                  ;;
                ddl)
                  SOURCE_PATH="dataproducts/${{ inputs.SOURCE }}/ddls/"
                  TARGET_PATH="${BASE_PATH}/dataproducts/${{ inputs.SOURCE }}/ddls/"
                  ;;
                dml)
                  SOURCE_PATH="dataproducts/${{ inputs.SOURCE }}/dmls/"
                  TARGET_PATH="${BASE_PATH}/dataproducts/${{ inputs.SOURCE }}/dmls/"
                  ;;
              esac

              echo "Deploying $step from $SOURCE_PATH to $TARGET_PATH"
              databricks workspace import_dir "$SOURCE_PATH" "$TARGET_PATH" --overwrite
              if [[ $? -ne 0 ]]; then
                echo "Error deploying $step files from $SOURCE_PATH"
                exit 1
              fi
            fi
          done

      - name: Cleanup
        run: |
          echo "Cleaning up temporary directories."
          rm -rf /tmp/cu/py/
          rm -rf /tmp/cu/ddl_dml/
