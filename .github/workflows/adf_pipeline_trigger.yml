name: Trigger ADF Pipeline

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        type: string
        required: true
      function_name:
        description: 'Data source'
        type: string
        required: true
      adf_pipeline_file:
        description: 'Pipeline JSON file name'
        type: string
        required: true
      date:
        description: 'Commit date'
        type: string
        required: true

env:
  ENVIRONMENT: ${{ inputs.environment }}
  DATE: ${{ inputs.date }}
  FUNCTION_NAME: ${{ inputs.function_name }}
  ADF_PIPELINE_FILE: ${{ inputs.adf_pipeline_file }}
  BRANCH: ${{ github.ref_name }}

jobs:
  trigger:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ github.ref_name }}

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Get changed files since provided date
        id: changed-files-since
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: "dataproducts/${{ env.FUNCTION_NAME }}/pipelines/"

      - name: Print changed files
        run: |
          echo "Changed files since date: ${{ steps.changed-files-since.outputs.all_changed_files }}"

      - name: Trigger ADF Pipeline
        run: |
          # Authentication for dev, qa, prod
          if [[ $ENVIRONMENT == 'dev' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT }}" --password "${{ secrets.CLIENTSECRET }}" --tenant "${{ secrets.TENANT }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID }}
            FACTORY_NAME="adf-psasdi-westus-dev-01"
            RESOURCE_GROUP="rg-psas-decision-intelligence-westus-dev"
          elif [[ $ENVIRONMENT == 'qa' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_QAT }}" --password "${{ secrets.CLIENT_SECRET_QAT }}" --tenant "${{ secrets.TENANT_ID_QAT }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID_QAT }}
            FACTORY_NAME="${{ secrets.FACTORY_NAME_QAT }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_QAT }}"
          elif [[ $ENVIRONMENT == 'prod' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_PROD }}" --password "${{ secrets.CLIENT_SECRET_PROD }}" --tenant "${{ secrets.TENANT_ID_PROD }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID_PROD }}
            FACTORY_NAME="${{ secrets.FACTORY_NAME_PROD }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_PROD }}"
          fi

          # Confirm authentication worked
          az account show

          echo "Logged in successfully"

          # Construct the full path to the pipeline JSON file
          PIPELINE_PATH="dataproducts/${{ env.FUNCTION_NAME }}/pipelines/${{ env.ADF_PIPELINE_FILE }}"

          # Check if the file exists and trigger the pipeline
          echo "Triggering pipeline from file: $PIPELINE_PATH"

          if [[ -f "$PIPELINE_PATH" ]]; then
            pipeline_name=${PIPELINE_PATH##*/}
            pipeline_name=${pipeline_name%.*}
            
            # Trigger the pipeline run on ADF using the JSON file content
            az datafactory pipeline create --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline @$PIPELINE_PATH --name "$pipeline_name"
            
            # Trigger the actual pipeline run using the same file as parameters
            az datafactory pipeline run --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline-name "$pipeline_name" --parameters "@$PIPELINE_PATH"
            
            echo "Pipeline $pipeline_name triggered successfully."
          else
            echo "Error: The file $PIPELINE_PATH does not exist."
            exit 1
          fi
