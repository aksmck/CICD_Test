name: Publish ADF Datasets

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        type: string
        required: true
      function_name:
        description: 'Data source'
        type: string
        required: true
      date:
        description: 'Commit date'
        type: string
        required: true

env:
  ENVIRONMENT: ${{ inputs.environment }}
  DATE: ${{ inputs.date }}
  FUNCTION_NAME: ${{ inputs.function_name }}
  BRANCH: ${{ github.ref_name }}

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ github.ref_name }}

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Install Azure CLI datafactory extension
        run: |
          az extension add --name datafactory

      - name: Get changed files since provided date
        id: changed-files-since
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: "dataproducts/${{ env.FUNCTION_NAME }}/datasets/"

      - name: Validate and Debug JSON Files
        run: |
          CHANGED_FILES="${{ steps.changed-files-since.outputs.all_changed_files }}"
          echo "Changed files: $CHANGED_FILES"

          if [[ -n "$CHANGED_FILES" ]]; then
            for file in $CHANGED_FILES; do
              echo "Processing file: $file"
              if [[ -f "$file" && "$file" == *.json ]]; then
                echo "File exists: $file"
                cat "$file"

                # Validate JSON structure
                if jq empty "$file"; then
                  echo "Valid JSON: $file"
                else
                  echo "Invalid JSON structure in: $file"
                  exit 1
                fi

                # Replace environment-specific variables in the JSON
                echo "Replacing placeholders in $file"
                VARIABLES_FILE="path/to/variables.json"

                # Check if the variables file exists
                if [[ -f "$VARIABLES_FILE" ]]; then
                  # Read the JSON file into a variable
                  VARIABLES_JSON=$(cat "$VARIABLES_FILE")

                  # Loop through all keys in the variables JSON and replace any corresponding placeholders in the dataset file
                  for key in $(echo "$VARIABLES_JSON" | jq -r 'keys[]'); do
                    value=$(echo "$VARIABLES_JSON" | jq -r ".${key}")
                    if [[ -n "$value" ]]; then
                      echo "Replacing placeholder: $$${key} with value: $value"

                      # Replace the placeholders in the dataset JSON file
                      jq --arg key "$key" --arg value "$value" \
                         'walk(if type == "string" then gsub("\\$\\$" + $key; $value) else . end)' \
                         "$file" > "${file}.updated"

                      mv "${file}.updated" "$file"
                    fi
                  done
                else
                  echo "Variables file not found: $VARIABLES_FILE"
                  exit 1
                fi
              else
                echo "File not found or invalid: $file"
                exit 1
              fi
            done
          else
            echo "No changed files detected."
            exit 0
          fi

      - name: Publish ADF Datasets
        run: |
          if [[ "$ENVIRONMENT" == "dev" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT }}" --password "${{ secrets.CLIENTSECRET }}" --tenant "${{ secrets.TENANT }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID }}"
            FACTORY_NAME="adf-psasdi-westus-dev-01"
            RESOURCE_GROUP="rg-psas-decision-intelligence-westus-dev"
          elif [[ "$ENVIRONMENT" == "qa" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_QAT }}" --password "${{ secrets.CLIENT_SECRET_QAT }}" --tenant "${{ secrets.TENANT_ID_QAT }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID_QAT }}"
            FACTORY_NAME="${{ secrets.FACTORY_NAME_QAT }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_QAT }}"
          elif [[ "$ENVIRONMENT" == "prod" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_PROD }}" --password "${{ secrets.CLIENT_SECRET_PROD }}" --tenant "${{ secrets.TENANT_ID_PROD }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID_PROD }}"
            FACTORY_NAME="${{ secrets.FACTORY_NAME_PROD }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_PROD }}"
          fi

          az account show
          echo "Logged in successfully"

          CHANGED_FILES="${{ steps.changed-files-since.outputs.all_changed_files }}"
          echo "Changed files to deploy: $CHANGED_FILES"

          if [[ -n "$CHANGED_FILES" ]]; then
            for file in $CHANGED_FILES; do
              echo "Processing file: $file"
              if [[ -f "$file" && "$file" == *.json ]]; then
                dataset_name=$(basename "$file" .json)
                echo "Deploying dataset: $dataset_name"

                # Print the content of the file to verify the JSON structure
                cat "$file"

                # Ensure that 'properties' exists and is not null or empty
                if jq -e '.properties' "$file" > /dev/null; then
                  # Fetch the Azure access token
                  token=$(az account get-access-token --query 'accessToken' -o tsv)

                  # Build the URL dynamically based on subscription ID, resource group, factory name, and dataset name
                  URL="https://management.azure.com/subscriptions/${{ secrets.SUBSCRIPTION_ID }}/resourceGroups/$RESOURCE_GROUP/providers/Microsoft.DataFactory/factories/$FACTORY_NAME/datasets/$dataset_name?api-version=2018-06-01"

                  # Use curl to deploy the dataset (PUT request)
                  response=$(curl -X PUT -H "Content-Type: application/json" \
                    -H "Authorization: Bearer $token" \
                    -d @"$file" "$URL" 2>&1)

                  echo "Response: $response"

                  if echo "$response" | grep -q 'error'; then
                    echo "Error deploying dataset: $dataset_name. Response: $response"
                    exit 1
                  else
                    echo "Successfully deployed dataset: $dataset_name"
                  fi
                else
                  echo "Error: 'properties' field is missing or empty in the file: $file"
                  exit 1
                fi
              else
                echo "Skipping invalid file: $file"
              fi
            done
          else
            echo "No dataset changes detected."
          fi
