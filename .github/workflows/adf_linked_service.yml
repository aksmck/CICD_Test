name: Publish ADF Datasets

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment (dev, qa, prod)'
        type: string
        required: true
      function_name:
        description: 'Data source function name'
        type: string
        required: true
      date:
        description: 'Commit date for detecting changes'
        type: string
        required: true

env:
  ENVIRONMENT: ${{ inputs.environment }}
  FUNCTION_NAME: ${{ inputs.function_name }}
  DATE: ${{ inputs.date }}
  BRANCH: ${{ github.ref_name }}

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ github.ref_name }}

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Install Azure CLI Data Factory Extension
        run: |
          az extension add --name datafactory

      - name: Get changed files since provided date
        id: changed-files
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: "dataproducts/${{ env.FUNCTION_NAME }}/datasets/"

      - name: Validate and Debug JSON Files
        run: |
          CHANGED_FILES="${{ steps.changed-files.outputs.all_changed_files }}"
          echo "Changed files: $CHANGED_FILES"

          if [[ -n "$CHANGED_FILES" ]]; then
            for file in $CHANGED_FILES; do
              echo "Processing file: $file"
              if [[ -f "$file" && "$file" == *.json ]]; then
                echo "Validating file: $file"
                cat "$file"

                if jq empty "$file"; then
                  echo "Valid JSON: $file"
                else
                  echo "Invalid JSON structure in: $file"
                  exit 1
                fi
              else
                echo "Skipping invalid or non-JSON file: $file"
              fi
            done
          else
            echo "No changed files detected."
            exit 0
          fi

      - name: Authenticate with Azure
        run: |
          if [[ "$ENVIRONMENT" == "dev" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT }}" --password "${{ secrets.CLIENTSECRET }}" --tenant "${{ secrets.TENANT }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID }}"
            FACTORY_NAME="adf-psasdi-westus-dev-01"
            RESOURCE_GROUP="rg-psas-decision-intelligence-westus-dev"
          elif [[ "$ENVIRONMENT" == "qa" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_QAT }}" --password "${{ secrets.CLIENT_SECRET_QAT }}" --tenant "${{ secrets.TENANT_ID_QAT }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID_QAT }}"
            FACTORY_NAME="${{ secrets.FACTORY_NAME_QAT }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_QAT }}"
          elif [[ "$ENVIRONMENT" == "prod" ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_PROD }}" --password "${{ secrets.CLIENT_SECRET_PROD }}" --tenant "${{ secrets.TENANT_ID_PROD }}"
            az account set -s "${{ secrets.SUBSCRIPTION_ID_PROD }}"
            FACTORY_NAME="${{ secrets.FACTORY_NAME_PROD }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_PROD }}"
          else
            echo "Error: Unsupported environment '$ENVIRONMENT'"
            exit 1
          fi
          az account show
          echo "Logged in successfully"

      - name: Deploy ADF Datasets
        run: |
          CHANGED_FILES="${{ steps.changed-files.outputs.all_changed_files }}"
          echo "Files to deploy: $CHANGED_FILES"

          if [[ -n "$CHANGED_FILES" ]]; then
            for file in $CHANGED_FILES; do
              echo "Processing file: $file"
              if [[ -f "$file" && "$file" == *.json ]]; then
                dataset_name=$(basename "$file" .json)
                echo "Deploying dataset: $dataset_name"
                cat "$file"

                if jq -e '.properties' "$file" > /dev/null; then
                  az datafactory dataset create \
                    --factory-name "$FACTORY_NAME" \
                    --resource-group "$RESOURCE_GROUP" \
                    --name "$dataset_name" \
                    --properties @"$file" || exit 1
                  echo "Successfully deployed: $dataset_name"
                else
                  echo "Error: 'properties' field is missing or empty in file: $file"
                  exit 1
                fi
              else
                echo "Skipping invalid or non-JSON file: $file"
              fi
            done
          else
            echo "No datasets to deploy."
          fi
