name: Publish ADF Pipelines

on:
  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment'
        type: string
        required: true
      function_name:
        description: 'Data source'
        type: string
        required: true
      adf_pipelines_deployment_steps:
        description: 'Pipeline steps'
        type: string
        required: true
      date:
        description: 'Commit date'
        type: string
        required: true
      trigger_pipeline:
        description: 'Whether to trigger the pipeline after deployment'
        type: boolean
        required: false
        default: false  # Default to false so it doesn't trigger unless the user opts for it

env:
  ENVIRONMENT: ${{ inputs.environment }}
  DATE: ${{ inputs.date }}
  FUNCTION_NAME: ${{ inputs.function_name }}
  ADF_PIPELINES_DEPLOYMENT_STEPS: ${{ inputs.adf_pipelines_deployment_steps }}
  BRANCH: ${{ github.ref_name }}
  TRIGGER_PIPELINE: ${{ inputs.trigger_pipeline }}

jobs:
  publish:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v2
        with:
          ref: ${{ github.ref_name }}

      - name: Install Azure CLI
        run: |
          curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash

      - name: Get changed files since provided date
        id: changed-files-since
        uses: tj-actions/changed-files@v37
        with:
          since: "${{ env.DATE }}"
          files: "dataproducts/${{ env.FUNCTION_NAME }}/pipelines/"

      - name: Print changed files
        run: |
          echo "Changed files since date: ${{ steps.changed-files-since.outputs.all_changed_files }}"

      - name: Check if there are changes for ADF pipeline steps
        run: |
          CHANGED_FILES="${{ steps.changed-files-since.outputs.all_changed_files }}"
          if [[ -z "$CHANGED_FILES" ]]; then
            echo "No changes detected for ${{ env.ADF_PIPELINES_DEPLOYMENT_STEPS }} after ${{ env.DATE }}."
            exit 0
          fi

      - name: Publish ADF Pipelines
        run: |
          # Authentication for dev, qa, prod
          if [[ $ENVIRONMENT == 'dev' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT }}" --password "${{ secrets.CLIENTSECRET }}" --tenant "${{ secrets.TENANT }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID }}
            FACTORY_NAME="adf-psasdi-westus-dev-01"
            RESOURCE_GROUP="rg-psas-decision-intelligence-westus-dev"
          elif [[ $ENVIRONMENT == 'qa' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_QAT }}" --password "${{ secrets.CLIENT_SECRET_QAT }}" --tenant "${{ secrets.TENANT_ID_QAT }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID_QAT }}
            FACTORY_NAME="${{ secrets.FACTORY_NAME_QAT }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_QAT }}"
          elif [[ $ENVIRONMENT == 'prod' ]]; then
            az login --service-principal --username "${{ secrets.CLIENT_ID_PROD }}" --password "${{ secrets.CLIENT_SECRET_PROD }}" --tenant "${{ secrets.TENANT_ID_PROD }}"
            az account set -s ${{ secrets.SUBSCRIPTION_ID_PROD }}
            FACTORY_NAME="${{ secrets.FACTORY_NAME_PROD }}"
            RESOURCE_GROUP="${{ secrets.RESOURCE_GROUP_PROD }}"
          fi

          # Confirm authentication worked
          az account show

          echo "Logged in successfully"

          # Deploy or Trigger Pipelines
          if [[ $ADF_PIPELINES_DEployment_STEPS == "all" ]]; then
            for file in ${{ steps.changed-files-since.outputs.all_changed_files }}; do
              if [[ $file == dataproducts/${{ env.FUNCTION_NAME }}/pipelines/* && $file == *".json" ]]; then
                echo "Deploying pipeline: $file"
                pipeline_name=${file##*/}  # Extract file name
                pipeline_name=${pipeline_name%.*}  # Remove file extension

                # Deploy pipeline
                az datafactory pipeline create --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline @$file --name "$pipeline_name"

                # Trigger pipeline if the user opted for it
                if [[ $TRIGGER_PIPELINE == true ]]; then
                  echo "Triggering pipeline: $pipeline_name"
                  az datafactory pipeline run --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline-name "$pipeline_name"
                fi
              fi
            done
          else
            echo "Deploying pipeline for ${{ env.ADF_PIPELINES_DEPLOYMENT_STEPS }} folder"
            folder="dataproducts/${{ env.FUNCTION_NAME }}/pipelines/${{ env.ADF_PIPELINES_DEPLOYMENT_STEPS }}/"
            for file in ${{ steps.changed-files-since.outputs.all_changed_files }}; do
              if [[ $file == $folder* && $file == *".json" ]]; then
                echo "Deploying pipeline from $ADF_PIPELINES_DEPLOYMENT_STEPS folder: $file"
                pipeline_name=${file##*/}
                pipeline_name=${pipeline_name%.*}

                # Deploy pipeline
                az datafactory pipeline create --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline @$file --name "$pipeline_name"

                # Trigger pipeline if the user opted for it
                if [[ $TRIGGER_PIPELINE == true ]]; then
                  echo "Triggering pipeline: $pipeline_name"
                  az datafactory pipeline run --factory-name $FACTORY_NAME --resource-group $RESOURCE_GROUP --pipeline-name "$pipeline_name"
                fi
              fi
            done
          fi
