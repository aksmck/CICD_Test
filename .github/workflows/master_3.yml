name: Master Deployment Workflow_3

on:
  workflow_dispatch:
    inputs:
      deployment_params:
        description: 'Deployment parameters (branch, environment, function_name)'
        type: string
        required: true
        default: '{"branch": "", "environment": "dev", "function_name": ""}'
      date:
        description: 'Deploy changes after a commit date (YYYY-MM-DD)'
        type: string
        default: '1999-01-01'
        required: true
      databricks_deployment_steps:
        description: 'Select Databricks deployment step'
        type: choice
        options:
          - none
          - ddl
          - dml
          - all
        required: false
        default: 'none'
      adf_pipelines_deployment_steps:
        description: 'Select ADF Pipelines deployment step'
        type: choice
        options:
          - none
          - all
          - landing
          - bronze
          - silver
          - gold
          - master
          - miscellaneous
        required: false
        default: 'none'
      deploy_linked_service:
        description: 'Deploy ADF Linked Services'
        type: boolean
        required: false
      deploy_datasets:
        description: 'Deploy ADF Datasets'
        type: boolean
        required: false
      deploy_triggers:
        description: 'Deploy ADF Triggers'
        type: boolean
        required: false
      deploy_dataflows:
        description: 'Deploy ADF Dataflows'
        type: boolean
        required: false

env:
  DEPLOYMENT_PARAMS: ${{ fromJson(inputs.deployment_params) }}
  DATE: ${{ inputs.date }}

jobs:
  validate_inputs:
    runs-on: ubuntu-latest
    steps:
      - name: Validate Inputs JSON Structure
        run: |
          echo "${{ inputs.deployment_params }}" | jq empty || { echo "Invalid JSON structure for deployment_params"; exit 1; }

      - name: Validate Date Format
        run: |
          if ! [[ "${{ env.DATE }}" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]; then
            echo "Invalid date format. Use YYYY-MM-DD."
            exit 1
          fi

      - name: Validate Future Date
        run: |
          if [[ "${{ env.DATE }}" > "$(date +%Y-%m-%d)" ]]; then
            echo "The specified date is in the future. Provide a valid past date."
            exit 1
          fi

      - name: Validate Environment Based on Branch
        run: |
          BRANCH="${{ env.DEPLOYMENT_PARAMS.branch }}"
          ENVIRONMENT="${{ env.DEPLOYMENT_PARAMS.environment }}"
          
          if [[ "$BRANCH" != "main" && "$ENVIRONMENT" == "prod" ]]; then
            echo "Production environment can only be deployed from the 'main' branch."
            exit 1
          fi

      - name: Validate Function Name
        run: |
          FUNCTION_NAME="${{ env.DEPLOYMENT_PARAMS.function_name }}"
          
          if [[ -z "$FUNCTION_NAME" ]]; then
            echo "Data source (function_name) cannot be empty."
            exit 1
          fi

      - name: Validate Deployment Inputs for ADF Steps 
        run: |
          if [[ "${{ inputs.deploy_linked_service }}" == "true" || "${{ inputs.deploy_datasets }}" == "true" || "${{ inputs.deploy_dataflows }}" == "true" ]]; then
            FUNCTION_NAME="${{ env.DEPLOYMENT_PARAMS.function_name }}"
            if [[ "$FUNCTION_NAME" == "none" ]]; then
              echo "If deploying linked services, datasets, or dataflows, a valid function name must be provided."
              exit 1
            fi
          fi

  trigger_workflows:
    name: Trigger Deployment Workflows
    needs: validate_inputs
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Repository
        uses: actions/checkout@v2
        with:
          ref: ${{ env.DEPLOYMENT_PARAMS.branch }}

      # Trigger Databricks Deployment if applicable 
      - name: Trigger Databricks Deployment 
        if: ${{ inputs.databricks_deployment_steps != 'none' }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "databricks_deployment_steps": "${{ inputs.databricks_deployment_steps }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/databricks.yml/dispatches 

      # Trigger ADF Pipelines Deployment 
      - name: Trigger ADF Pipelines Deployment 
        if: ${{ inputs.adf_pipelines_deployment_steps != 'none' }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "adf_pipelines_deployment_steps": "${{ inputs.adf_pipelines_deployment_steps }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/adf_pipelines.yml/dispatches 

      # Trigger ADF Linked Services Deployment 
      - name: Trigger ADF Linked Services Deployment 
        if: ${{ inputs.deploy_linked_service == true }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/adf_linked_service.yml/dispatches 

      # Trigger ADF Datasets Deployment 
      - name: Trigger ADF Datasets Deployment 
        if: ${{ inputs.deploy_datasets == true }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/adf_dataset.yml/dispatches 

      # Trigger ADF Triggers Deployment 
      - name: Trigger ADF Triggers Deployment 
        if: ${{ inputs.deploy_triggers == true }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/adf_trigger.yml/dispatches 

      # Trigger ADF Dataflows Deployment 
      - name: Trigger ADF Dataflows Deployment 
        if: ${{ inputs.deploy_dataflows == true }} 
        run: | 
          curl -X POST \ 
            -H "Authorization: Bearer ${{ secrets.GITHUB_TOKEN }}" \ 
            -d '{"ref": "refs/heads/${{ env.DEPLOYMENT_PARAMS.branch }}", "inputs": {"environment": "${{ env.DEPLOYMENT_PARAMS.environment }}", "date": "${{ env.DATE }}", "function_name": "${{ env.DEPLOYMENT_PARAMS.function_name }}"}}' \ 
            https://api.github.com/repos/${{ github.repository }}/actions/workflows/adf_dataflows.yml/dispatches 
